{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 2810: expected 2 fields, saw 5\\nSkipping line 4641: expected 2 fields, saw 5\\nSkipping line 7171: expected 2 fields, saw 5\\nSkipping line 11220: expected 2 fields, saw 5\\nSkipping line 13809: expected 2 fields, saw 5\\nSkipping line 14132: expected 2 fields, saw 5\\nSkipping line 14293: expected 2 fields, saw 5\\nSkipping line 14865: expected 2 fields, saw 5\\nSkipping line 17419: expected 2 fields, saw 5\\nSkipping line 22801: expected 2 fields, saw 5\\nSkipping line 25001: expected 2 fields, saw 5\\nSkipping line 26603: expected 2 fields, saw 5\\nSkipping line 26742: expected 2 fields, saw 5\\nSkipping line 29702: expected 2 fields, saw 5\\nSkipping line 32767: expected 2 fields, saw 5\\nSkipping line 32878: expected 2 fields, saw 5\\nSkipping line 35643: expected 2 fields, saw 5\\nSkipping line 36550: expected 2 fields, saw 5\\nSkipping line 38732: expected 2 fields, saw 5\\nSkipping line 40567: expected 2 fields, saw 5\\nSkipping line 40576: expected 2 fields, saw 5\\nSkipping line 41864: expected 2 fields, saw 5\\nSkipping line 46861: expected 2 fields, saw 5\\nSkipping line 47939: expected 2 fields, saw 5\\nSkipping line 48628: expected 2 fields, saw 5\\nSkipping line 48908: expected 2 fields, saw 5\\nSkipping line 57582: expected 2 fields, saw 5\\nSkipping line 58782: expected 2 fields, saw 5\\nSkipping line 58984: expected 2 fields, saw 5\\nSkipping line 61518: expected 2 fields, saw 5\\nSkipping line 63451: expected 2 fields, saw 5\\nSkipping line 68141: expected 2 fields, saw 5\\nSkipping line 72083: expected 2 fields, saw 5\\nSkipping line 74027: expected 2 fields, saw 5\\nSkipping line 77811: expected 2 fields, saw 5\\nSkipping line 83958: expected 2 fields, saw 5\\nSkipping line 85295: expected 2 fields, saw 5\\nSkipping line 88665: expected 2 fields, saw 5\\nSkipping line 89198: expected 2 fields, saw 5\\nSkipping line 92499: expected 2 fields, saw 5\\nSkipping line 92751: expected 2 fields, saw 5\\nSkipping line 93689: expected 2 fields, saw 5\\nSkipping line 94776: expected 2 fields, saw 5\\nSkipping line 97334: expected 2 fields, saw 5\\nSkipping line 102316: expected 2 fields, saw 5\\nSkipping line 103421: expected 2 fields, saw 5\\nSkipping line 106872: expected 2 fields, saw 5\\nSkipping line 109363: expected 2 fields, saw 5\\nSkipping line 110117: expected 2 fields, saw 5\\nSkipping line 110465: expected 2 fields, saw 5\\nSkipping line 113843: expected 2 fields, saw 5\\nSkipping line 115634: expected 2 fields, saw 5\\nSkipping line 121518: expected 2 fields, saw 5\\nSkipping line 123692: expected 2 fields, saw 5\\nSkipping line 124708: expected 2 fields, saw 5\\nSkipping line 129608: expected 2 fields, saw 5\\nSkipping line 133176: expected 2 fields, saw 5\\nSkipping line 135532: expected 2 fields, saw 5\\nSkipping line 138042: expected 2 fields, saw 5\\nSkipping line 139485: expected 2 fields, saw 5\\nSkipping line 140401: expected 2 fields, saw 5\\nSkipping line 144093: expected 2 fields, saw 5\\nSkipping line 149850: expected 2 fields, saw 5\\nSkipping line 151831: expected 2 fields, saw 5\\nSkipping line 158014: expected 2 fields, saw 5\\nSkipping line 162047: expected 2 fields, saw 5\\nSkipping line 164515: expected 2 fields, saw 5\\nSkipping line 170313: expected 2 fields, saw 5\\nSkipping line 171325: expected 2 fields, saw 5\\nSkipping line 171424: expected 2 fields, saw 5\\nSkipping line 175920: expected 2 fields, saw 5\\nSkipping line 176210: expected 2 fields, saw 5\\nSkipping line 183603: expected 2 fields, saw 5\\nSkipping line 190264: expected 2 fields, saw 5\\nSkipping line 191683: expected 2 fields, saw 5\\nSkipping line 191988: expected 2 fields, saw 5\\nSkipping line 195450: expected 2 fields, saw 5\\nSkipping line 195754: expected 2 fields, saw 5\\nSkipping line 197124: expected 2 fields, saw 5\\nSkipping line 199263: expected 2 fields, saw 5\\nSkipping line 202603: expected 2 fields, saw 5\\nSkipping line 209960: expected 2 fields, saw 5\\nSkipping line 213218: expected 2 fields, saw 5\\nSkipping line 217060: expected 2 fields, saw 5\\nSkipping line 220121: expected 2 fields, saw 5\\nSkipping line 223518: expected 2 fields, saw 5\\nSkipping line 226293: expected 2 fields, saw 5\\nSkipping line 227035: expected 2 fields, saw 7\\nSkipping line 227341: expected 2 fields, saw 5\\nSkipping line 227808: expected 2 fields, saw 5\\nSkipping line 228516: expected 2 fields, saw 5\\nSkipping line 228733: expected 2 fields, saw 5\\nSkipping line 232043: expected 2 fields, saw 5\\nSkipping line 232426: expected 2 fields, saw 5\\nSkipping line 234490: expected 2 fields, saw 5\\nSkipping line 239626: expected 2 fields, saw 5\\nSkipping line 240461: expected 2 fields, saw 5\\nSkipping line 244518: expected 2 fields, saw 5\\nSkipping line 245395: expected 2 fields, saw 5\\nSkipping line 246168: expected 2 fields, saw 5\\nSkipping line 246655: expected 2 fields, saw 5\\nSkipping line 246752: expected 2 fields, saw 5\\nSkipping line 247189: expected 2 fields, saw 5\\nSkipping line 250276: expected 2 fields, saw 5\\nSkipping line 255327: expected 2 fields, saw 5\\nSkipping line 257094: expected 2 fields, saw 5\\n'\n",
      "b'Skipping line 264626: expected 2 fields, saw 5\\nSkipping line 265028: expected 2 fields, saw 5\\nSkipping line 269150: expected 2 fields, saw 5\\nSkipping line 271360: expected 2 fields, saw 5\\nSkipping line 273975: expected 2 fields, saw 5\\nSkipping line 274742: expected 2 fields, saw 5\\nSkipping line 276227: expected 2 fields, saw 5\\nSkipping line 279807: expected 2 fields, saw 5\\nSkipping line 283425: expected 2 fields, saw 5\\nSkipping line 287468: expected 2 fields, saw 5\\nSkipping line 292995: expected 2 fields, saw 5\\nSkipping line 293496: expected 2 fields, saw 5\\nSkipping line 293735: expected 2 fields, saw 5\\nSkipping line 295060: expected 2 fields, saw 5\\nSkipping line 296643: expected 2 fields, saw 5\\nSkipping line 296848: expected 2 fields, saw 5\\nSkipping line 308926: expected 2 fields, saw 5\\nSkipping line 310360: expected 2 fields, saw 5\\nSkipping line 317004: expected 2 fields, saw 5\\nSkipping line 318207: expected 2 fields, saw 5\\nSkipping line 331783: expected 2 fields, saw 5\\nSkipping line 333864: expected 2 fields, saw 5\\nSkipping line 335958: expected 2 fields, saw 5\\nSkipping line 336290: expected 2 fields, saw 5\\nSkipping line 343526: expected 2 fields, saw 5\\nSkipping line 343857: expected 2 fields, saw 5\\nSkipping line 344059: expected 2 fields, saw 5\\nSkipping line 348691: expected 2 fields, saw 5\\nSkipping line 353446: expected 2 fields, saw 5\\nSkipping line 357073: expected 2 fields, saw 5\\nSkipping line 359753: expected 2 fields, saw 5\\nSkipping line 359974: expected 2 fields, saw 5\\nSkipping line 366534: expected 2 fields, saw 5\\nSkipping line 369514: expected 2 fields, saw 5\\nSkipping line 377759: expected 2 fields, saw 5\\nSkipping line 379327: expected 2 fields, saw 5\\nSkipping line 380769: expected 2 fields, saw 5\\nSkipping line 381073: expected 2 fields, saw 5\\nSkipping line 381489: expected 2 fields, saw 5\\nSkipping line 386304: expected 2 fields, saw 5\\nSkipping line 387635: expected 2 fields, saw 5\\nSkipping line 389613: expected 2 fields, saw 5\\nSkipping line 392604: expected 2 fields, saw 5\\nSkipping line 393184: expected 2 fields, saw 5\\nSkipping line 395530: expected 2 fields, saw 5\\nSkipping line 396939: expected 2 fields, saw 5\\nSkipping line 397385: expected 2 fields, saw 5\\nSkipping line 397509: expected 2 fields, saw 5\\nSkipping line 402902: expected 2 fields, saw 5\\nSkipping line 405187: expected 2 fields, saw 5\\nSkipping line 408412: expected 2 fields, saw 5\\nSkipping line 419423: expected 2 fields, saw 5\\nSkipping line 420962: expected 2 fields, saw 5\\nSkipping line 425965: expected 2 fields, saw 5\\nSkipping line 427496: expected 2 fields, saw 5\\nSkipping line 438881: expected 2 fields, saw 5\\nSkipping line 439776: expected 2 fields, saw 5\\nSkipping line 440345: expected 2 fields, saw 5\\nSkipping line 445507: expected 2 fields, saw 5\\nSkipping line 445548: expected 2 fields, saw 5\\nSkipping line 447184: expected 2 fields, saw 5\\nSkipping line 448603: expected 2 fields, saw 5\\nSkipping line 451732: expected 2 fields, saw 5\\nSkipping line 458249: expected 2 fields, saw 5\\nSkipping line 460274: expected 2 fields, saw 5\\nSkipping line 467630: expected 2 fields, saw 5\\nSkipping line 473961: expected 2 fields, saw 5\\nSkipping line 476281: expected 2 fields, saw 5\\nSkipping line 478010: expected 2 fields, saw 5\\nSkipping line 478322: expected 2 fields, saw 5\\nSkipping line 479999: expected 2 fields, saw 5\\nSkipping line 480898: expected 2 fields, saw 5\\nSkipping line 481688: expected 2 fields, saw 5\\nSkipping line 485193: expected 2 fields, saw 5\\nSkipping line 485519: expected 2 fields, saw 5\\nSkipping line 486000: expected 2 fields, saw 5\\nSkipping line 489063: expected 2 fields, saw 5\\nSkipping line 494525: expected 2 fields, saw 5\\nSkipping line 495009: expected 2 fields, saw 5\\nSkipping line 501954: expected 2 fields, saw 5\\nSkipping line 508035: expected 2 fields, saw 5\\nSkipping line 508828: expected 2 fields, saw 5\\nSkipping line 509833: expected 2 fields, saw 5\\nSkipping line 510410: expected 2 fields, saw 5\\nSkipping line 518229: expected 2 fields, saw 5\\nSkipping line 520302: expected 2 fields, saw 5\\nSkipping line 520340: expected 2 fields, saw 5\\n'\n",
      "b'Skipping line 525174: expected 2 fields, saw 5\\nSkipping line 526251: expected 2 fields, saw 5\\nSkipping line 529611: expected 2 fields, saw 5\\nSkipping line 531398: expected 2 fields, saw 5\\nSkipping line 534146: expected 2 fields, saw 5\\nSkipping line 544954: expected 2 fields, saw 5\\nSkipping line 553002: expected 2 fields, saw 5\\nSkipping line 553883: expected 2 fields, saw 5\\nSkipping line 553887: expected 2 fields, saw 5\\nSkipping line 553915: expected 2 fields, saw 5\\nSkipping line 554172: expected 2 fields, saw 5\\nSkipping line 563534: expected 2 fields, saw 5\\nSkipping line 565191: expected 2 fields, saw 5\\nSkipping line 574108: expected 2 fields, saw 5\\nSkipping line 574412: expected 2 fields, saw 5\\nSkipping line 575985: expected 2 fields, saw 5\\nSkipping line 580091: expected 2 fields, saw 5\\nSkipping line 582682: expected 2 fields, saw 5\\nSkipping line 585885: expected 2 fields, saw 5\\nSkipping line 590171: expected 2 fields, saw 5\\nSkipping line 591924: expected 2 fields, saw 5\\nSkipping line 592515: expected 2 fields, saw 5\\nSkipping line 593888: expected 2 fields, saw 5\\nSkipping line 596245: expected 2 fields, saw 5\\nSkipping line 607344: expected 2 fields, saw 5\\nSkipping line 607633: expected 2 fields, saw 5\\nSkipping line 610939: expected 2 fields, saw 5\\nSkipping line 613638: expected 2 fields, saw 5\\nSkipping line 615643: expected 2 fields, saw 5\\nSkipping line 615901: expected 2 fields, saw 5\\nSkipping line 617389: expected 2 fields, saw 5\\nSkipping line 634641: expected 2 fields, saw 5\\nSkipping line 635755: expected 2 fields, saw 5\\nSkipping line 646243: expected 2 fields, saw 5\\nSkipping line 647165: expected 2 fields, saw 5\\nSkipping line 648610: expected 2 fields, saw 5\\nSkipping line 648772: expected 2 fields, saw 5\\nSkipping line 651833: expected 2 fields, saw 5\\nSkipping line 653663: expected 2 fields, saw 5\\nSkipping line 656233: expected 2 fields, saw 5\\nSkipping line 656694: expected 2 fields, saw 5\\nSkipping line 659783: expected 2 fields, saw 5\\nSkipping line 660478: expected 2 fields, saw 5\\nSkipping line 661133: expected 2 fields, saw 5\\nSkipping line 661736: expected 2 fields, saw 5\\nSkipping line 669827: expected 2 fields, saw 5\\n'\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\",',', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>password</th>\n",
       "      <th>strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kzde5577</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kino3434</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>visi7k1yr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>megzy123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lamborghin1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      password  strength\n",
       "0     kzde5577         1\n",
       "1     kino3434         1\n",
       "2    visi7k1yr         1\n",
       "3     megzy123         1\n",
       "4  lamborghin1         1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>password</th>\n",
       "      <th>strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>367579</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       password  strength\n",
       "367579      NaN         0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['password'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "passwords_tuple = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['kzde5577', 1],\n",
       "       ['kino3434', 1],\n",
       "       ['visi7k1yr', 1],\n",
       "       ...,\n",
       "       ['184520socram', 1],\n",
       "       ['marken22a', 1],\n",
       "       ['fxx4pw4g', 1]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passwords_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the 2d array randomly\n",
    "import random\n",
    "random.shuffle(passwords_tuple) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [labels[1] for labels in passwords_tuple]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [labels[0] for labels in passwords_tuple]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x153df08aac8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x='strength',data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    496801\n",
       "0     89701\n",
       "2     83137\n",
       "Name: strength, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['strength'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_chars(word):\n",
    "    characters = []\n",
    "    for char in word:\n",
    "        characters.append(char)\n",
    "    return characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## By default TfidfVectorizer uses words as tokenizer to create feature. In our case, each word is unique and thus will create\n",
    "## more than 6 lakhs vectors which is very hard to train. Thus we will use a tokenizer which is a function which breaks the words\n",
    "## into characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "vectorizer = TfidfVectorizer(tokenizer=word_to_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vect = vectorizer.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k': 57,\n",
       " 'z': 72,\n",
       " 'd': 50,\n",
       " 'e': 51,\n",
       " '5': 30,\n",
       " '7': 32,\n",
       " 'i': 55,\n",
       " 'n': 60,\n",
       " 'o': 61,\n",
       " '3': 28,\n",
       " '4': 29,\n",
       " 'v': 68,\n",
       " 's': 65,\n",
       " '1': 26,\n",
       " 'y': 71,\n",
       " 'r': 64,\n",
       " 'l': 58,\n",
       " 'a': 47,\n",
       " 'm': 59,\n",
       " 'b': 48,\n",
       " 'g': 53,\n",
       " 'h': 54,\n",
       " 'q': 63,\n",
       " 'f': 52,\n",
       " 't': 66,\n",
       " 'u': 67,\n",
       " '6': 31,\n",
       " 'c': 49,\n",
       " '8': 33,\n",
       " 'w': 69,\n",
       " '9': 34,\n",
       " '0': 25,\n",
       " 'p': 62,\n",
       " 'j': 56,\n",
       " '2': 27,\n",
       " '-': 22,\n",
       " '@': 40,\n",
       " 'x': 70,\n",
       " '!': 12,\n",
       " '.': 23,\n",
       " '&': 17,\n",
       " '?': 39,\n",
       " '>': 38,\n",
       " '<': 36,\n",
       " ';': 35,\n",
       " '_': 45,\n",
       " '±': 85,\n",
       " '%': 16,\n",
       " '$': 15,\n",
       " '/': 24,\n",
       " '(': 18,\n",
       " ')': 19,\n",
       " ' ': 11,\n",
       " '^': 44,\n",
       " '#': 14,\n",
       " 'ú': 115,\n",
       " '*': 20,\n",
       " '+': 21,\n",
       " '{': 73,\n",
       " '}': 75,\n",
       " '=': 37,\n",
       " '[': 41,\n",
       " ']': 43,\n",
       " '\\x1c': 8,\n",
       " '³': 87,\n",
       " '\"': 13,\n",
       " '~': 76,\n",
       " '\\\\': 42,\n",
       " '`': 46,\n",
       " '\\x16': 5,\n",
       " 'ó': 110,\n",
       " 'ò': 109,\n",
       " '·': 89,\n",
       " '\\x1e': 10,\n",
       " '¿': 92,\n",
       " 'þ': 119,\n",
       " 'å': 98,\n",
       " '‚': 122,\n",
       " '«': 83,\n",
       " 'ß': 93,\n",
       " 'ä': 97,\n",
       " 'à': 94,\n",
       " 'ô': 111,\n",
       " '²': 86,\n",
       " '|': 74,\n",
       " 'ð': 107,\n",
       " 'â': 96,\n",
       " '\\x10': 3,\n",
       " '\\x17': 6,\n",
       " '\\x19': 7,\n",
       " '¾': 91,\n",
       " '\\x7f': 77,\n",
       " '\\x08': 2,\n",
       " 'ê': 103,\n",
       " 'á': 95,\n",
       " 'ÿ': 120,\n",
       " 'õ': 112,\n",
       " 'í': 104,\n",
       " '÷': 114,\n",
       " '¡': 80,\n",
       " '¨': 82,\n",
       " 'ü': 117,\n",
       " 'û': 116,\n",
       " '°': 84,\n",
       " '—': 121,\n",
       " 'ö': 113,\n",
       " 'º': 90,\n",
       " 'é': 102,\n",
       " '\\x06': 1,\n",
       " 'ý': 118,\n",
       " 'µ': 88,\n",
       " 'ç': 100,\n",
       " 'ñ': 108,\n",
       " '\\xa0': 79,\n",
       " 'æ': 99,\n",
       " 'è': 101,\n",
       " '‡': 123,\n",
       " '\\x13': 4,\n",
       " '\\x1d': 9,\n",
       " 'î': 105,\n",
       " 'ï': 106,\n",
       " '\\x05': 0,\n",
       " '¤': 81,\n",
       " '\\x81': 78}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          kzde5577\n",
       "1                          kino3434\n",
       "2                         visi7k1yr\n",
       "3                          megzy123\n",
       "4                       lamborghin1\n",
       "5                  AVYq1lDE4MgAZfNt\n",
       "6                          u6c8vhow\n",
       "7                          v1118714\n",
       "8                      universe2908\n",
       "9                          as326159\n",
       "10                         asv5o9yu\n",
       "11                     612035180tok\n",
       "12                       jytifok873\n",
       "13                 WUt9IZzE0OQ7PkNE\n",
       "14                     jerusalem393\n",
       "15                       g067057895\n",
       "16                      52558000aaa\n",
       "17                         idofo673\n",
       "18                        6975038lp\n",
       "19                        sbl571017\n",
       "20              elyass15@ajilent-ci\n",
       "21                           intel1\n",
       "22                 klara-tershina3H\n",
       "23                       czuodhj972\n",
       "24                      faranumar91\n",
       "25                      cigicigi123\n",
       "26                      0169395484a\n",
       "27                        schalke04\n",
       "28                     prisonbreak1\n",
       "29                        asgaliu11\n",
       "                    ...            \n",
       "669610                0933674790MAK\n",
       "669611                   lmfao12345\n",
       "669612              MeRAquFABUZy226\n",
       "669613                    paulooos2\n",
       "669614                yim0843976474\n",
       "669615                   eydcivmuj9\n",
       "669616                    fireyice7\n",
       "669617                    xlepjrf75\n",
       "669618    juanpaganini588@gmail.com\n",
       "669619             tYAam8zg3Mg2AZ7a\n",
       "669620                   7598692aaa\n",
       "669621                    ain151090\n",
       "669622             weslley.06888524\n",
       "669623                    nt7hm2p5w\n",
       "669624                 dxipqgtch507\n",
       "669625                   skate11223\n",
       "669626                  reeta456456\n",
       "669627               sakaryal&#305;\n",
       "669628                    mario3391\n",
       "669629                     wen2cin2\n",
       "669630                    mywude577\n",
       "669631             8rp4PTTM1MAlcLw0\n",
       "669632                    hattrick9\n",
       "669633                    lanciau01\n",
       "669634                       sh4tup\n",
       "669635                   10redtux10\n",
       "669636                    infrared1\n",
       "669637                 184520socram\n",
       "669638                    marken22a\n",
       "669639                     fxx4pw4g\n",
       "Name: password, Length: 669639, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_vect, y, test_size=0.20, random_state=42)  #splitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Debayan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Debayan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8126978675109013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Debayan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "log_class = LogisticRegression(penalty='l2',multi_class='ovr')\n",
    "log_class.fit(X_train, y_train)\n",
    "print(log_class.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8199330983812197\n"
     ]
    }
   ],
   "source": [
    "## Multinomial\n",
    "\n",
    "clf = LogisticRegression(random_state=0, multi_class='multinomial', solver='newton-cg')\n",
    "clf.fit(X_train, y_train) #training\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "X_predict=np.array([\"jerusalem\"])\n",
    "X_predict=vectorizer.transform(X_predict)\n",
    "y_pred=log_class.predict(X_predict)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier = xgb.XGBClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(objective='multi:softprob')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9145660354817514"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "X_predict=np.array([\"password@12314%^&\"])\n",
    "X_predict=vectorizer.transform(X_predict)\n",
    "y_pred=xgb_classifier.predict(X_predict)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "appfile = open(\"PassCheck_XGBoost.pkl\",\"wb\")\n",
    "vectorfile = open(\"vectorizer.pkl\",\"wb\")\n",
    "pickle.dump(xgb_classifier, appfile)\n",
    "pickle.dump(vectorizer,vectorfile)\n",
    "appfile.close()\n",
    "vectorfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "appfile = open(\"PassCheck_XGBoost.pkl\",\"rb\")\n",
    "model = pickle.load(appfile)\n",
    "X_predict=np.array([\"password@12314%^&\"])\n",
    "X_predict=vectorizer.transform(X_predict)\n",
    "y_pred=model.predict(X_predict)\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
